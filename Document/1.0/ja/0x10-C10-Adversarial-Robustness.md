# C10 敵対的堅牢性とプライバシー防御 (Adversarial Robustness & Privacy Defense)

## 管理目標

回避、推論、抽出、またはポイズニング攻撃に直面した場合でも、AI モデルが信頼性、プライバシー保護、不正使用耐性を維持することを確保します。

---

## 10.1 モデルの整合と安全性 (Model Alignment & Safety)

有害な出力やポリシー違反の出力をガードします。

| # | 説明 | レベル | ロール |
|:--------:|---------------------------------------------------------------------------------------------------------------------|:---:|:---:|
| **10.1.1** | **検証:** アライメントテストスイート (レッドチームプロンプト、ジェイルブレイクプローブ、許可されていないコンテンツ) はバージョン管理されており、すべてのモデルリリースで実行している。 | 1 | D/V |
| **10.1.2** | **検証:** 拒否と安全な完了のガードレールは実施されている。 | 1 | D |
| **10.1.3** | **検証:** 自動評価器は有害コンテンツ率を測定し、設定した閾値を超える回帰にフラグ付けしている。 | 2 | D/V |
| **10.1.4** | **検証:** ジェイルブレイク対策トレーニングは文書化されており、再現可能である。 | 2 | D |
| **10.1.5** | **検証:** 形式ポリシーコンプライアンス証明または認定モニタリングは重要なドメインをカバーしている。 | 3 | V |

---

## 10.2 敵対的サンプルの堅牢化 (Adversarial-Example Hardening)

操作された入力に対する耐性を高めます。堅牢な敵対的トレーニングとベンチマークスコアリングが現在のベストプラクティスです。

| # | 説明 | レベル | ロール |
|:--------:|---------------------------------------------------------------------------------------------------------------------|:---:|:---:|
| **10.2.1** | **検証:** プロジェクトリポジトリは、再現可能なシードでの敵対的トレーニング構成を含んでいる。 | 1 | D |
| **10.2.2** | **検証:** 敵対的サンプル検出は本番パイプラインでブロックアラートを発している。 | 2 | D/V |
| **10.2.4** | **検証:** 認定された堅牢性の証明または区間境界証明書は少なくとも最上位の重要なクラスをカバーしている。 | 3 | V |
| **10.2.5** | **検証:** 回帰テストは、測定可能な堅牢性の損失がないことを確認するために、適応型攻撃を使用している。 | 3 | V |

---

## 10.3 メンバーシップ推論の緩和 (Membership-Inference Mitigation)

レコードがトレーニングデータにあるかどうかを判断する能力を制限します。差分プライバシーと信頼スコアマスキングは依然として最も効果的な既知の防御策です。

| # | 説明 | レベル | ロール |
|:--------:|---------------------------------------------------------------------------------------------------------------------|:---:|:---:|
| **10.3.1** | **検証:** クエリごとのエントロピー正則化または温度スケーリングは過信した予測を削減している。 | 1 | D |
| **10.3.2** | **検証:** トレーニングは機密データセットに対して ε 境界の差分プライベート最適化を採用している。 | 2 | D |
| **10.3.3** | **検証:** 攻撃シミュレーション (シャドウモデルまたはブラックボックス) はホールドアウトデータに対して攻撃 AUC ≤ 0.60 を示している。 | 2 | V |

---

## 10.4 モデル反転の耐性 (Model-Inversion Resistance)

プライベート属性の再構築を防止します。最近の調査では出力の切り捨てと DP 保証を実用的な防御策として重視しています。

| # | 説明 | レベル | ロール |
|:--------:|---------------------------------------------------------------------------------------------------------------------|:---:|:---:|
| **10.4.1** | **検証:** 機密属性は決して直接出力されることがない。必要な場合は、バケットまたは一方向変換を使用している。 | 1 | D |
| **10.4.2** | **検証:** クエリレート制限は同じプリンシパルからの繰り返しの適応型クエリを抑制している。 | 1 | D/V |
| **10.4.3** | **検証:** モデルはプライバシーを保護するノイズを用いて訓練されている。 | 2 | D |

---

## 10.5 モデル抽出の防御 (Model-Extraction Defense)

不正なクローニングを検出して阻止します。透かし入れとクエリパターン解析が推奨されています。

| # | 説明 | レベル | ロール |
|:--------:|---------------------------------------------------------------------------------------------------------------------|:---:|:---:|
| **10.5.1** | **検証:** 推論ゲートウェイは、モデルのメモ化閾値に合わせて調整された、グローバルおよび API キーごとのレート制限を適用している。 | 1 | D |
| **10.5.2** | **検証:** クエリエントロピーと入力の複数性の統計は自動抽出検出器に供給している。 | 2 | D/V |
| **10.5.3** | **検証:** 脆弱な透かしや確率的な透かしは、疑わしいクローンに対して 1000 クエリ以下のクエリで p < 0.01 で証明できる。 | 2 | V |
| **10.5.4** | **検証:** 透かしの鍵とトリガーのセットはハードウェアセキュリティモジュールに保存されており、毎年入れ替えられている。 | 3 | D |
| **10.5.5** | **検証:** 抽出アラートイベントは問題のあるクエリを含んでおり、インシデント対応プレイブックと統合されている。 | 3 | V |

---

## 10.6 推論時の汚染データ検出 (Inference-Time Poisoned-Data Detection)

バックドアのある入力や汚染された入力を識別して無効化します。

| # | 説明 | レベル | ロール |
|:--------:|---------------------------------------------------------------------------------------------------------------------|:---:|:---:|
| **10.6.1** | **検証:** 入力は、モデル推論前に、異常検出器 (STRIP、一貫性スコアリング) を通過している。 | 1 | D |
| **10.6.2** | **検証:** 検出器閾値は、誤検出率 5% 未満になるように、清浄/汚染バリデーションセットを調整されている。 | 1 | V |
| **10.6.3** | **検証:** 汚染ありとフラグ付けされた入力はソフトブロッキングと人間によるレビューワークフローをトリガーしている。 | 2 | D |
| **10.6.4** | **検証:** 検出器は、適応型のトリガーレスバックドア攻撃で、ストレステストされている。 | 2 | V |
| **10.6.5** | **検証:** 検出有効性メトリクスはログ記録されており、最新の脅威インテリジェンスで定期的に再評価されている。 | 3 | D |

---

## 10.7 動的セキュリティポリシー適応 (Dynamic Security Policy Adaptation)

脅威インテリジェンスと行動分析に基づいたリアルタイムのセキュリティポリシー更新です。

| # | 説明 | レベル | ロール |
|:--------:|---------------------------------------------------------------------------------------------------------------------|:---:|:---:|
| **10.7.1** | **検証:** セキュリティポリシーは、ポリシーバージョンの完全性を維持しながら、エージェントを再起動せずに動的に更新できる。 | 1 | D/V |
| **10.7.2** | **検証:** ポリシーの更新は認可されたセキュリティ担当者によって暗号署名され、適用前に検証されている。 | 2 | D/V |
| **10.7.3** | **検証:** 動的なポリシーの変更は、正当性、承認チェーン、ロールバック手順を含む完全な監査証跡とともにログ記録されている。 | 2 | D/V |
| **10.7.4** | **検証:** 適応型セキュリティメカニズムは、リスクの状況と行動パターンに基づいて、脅威検出の感度を調整している。 | 3 | D/V |
| **10.7.5** | **検証:** ポリシー適応の決定は説明可能であり、セキュリティチームレビューのために証拠の証跡を含んでいる。 | 3 | D/V |

---

## 10.8 リフレクションベースのセキュリティ分析 (Reflection-Based Security Analysis)

エージェントのセルフリフレクションとメタ認知分析を通じたセキュリティバリデーションです。

| # | 説明 | レベル | ロール |
|:--------:|---------------------------------------------------------------------------------------------------------------------|:---:|:---:|
| **10.8.1** | **検証:** エージェントのリフレクションメカニズムは、セキュリティに重点を置いた、意思決定とアクションの自己評価を含んでいる。 | 1 | D/V |
| **10.8.2** | **検証:** リフレクション出力は、敵対的な入力による自己評価メカニズムの操作を防ぐために、検証されている。 | 2 | D/V |
| **10.8.3** | **検証:** メタ認知セキュリティ分析は、エージェントの推論プロセスにおける潜在的なバイアス、操作、侵害を特定している。 | 2 | D/V |
| **10.8.4** | **検証:** リフレクションベースのセキュリティ警告は、強化された監視と潜在的な人間の介入ワークフローをトリガーしている。 | 3 | D/V |
| **10.8.5** | **検証:** セキュリティリフレクションからの継続的な学習は、正当な機能を劣化することなく、脅威の検出を向上している。 | 3 | D/V |

---

## 10.9 セキュリティの進化と自己改善 (Evolution & Self-Improvement Security)

Security controls for agent systems capable of self-modification and evolution.

| # | 説明 | レベル | ロール |
|:--------:|---------------------------------------------------------------------------------------------------------------------|:---:|:---:|
| **10.9.1** | **Verify that** self-modification capabilities are restricted to designated safe areas with formal verification boundaries. | 1 | D/V |
| **10.9.2** | **Verify that** evolution proposals undergo security impact assessment before implementation. | 2 | D/V |
| **10.9.3** | **Verify that** self-improvement mechanisms include rollback capabilities with integrity verification. | 2 | D/V |
| **10.9.4** | **Verify that** meta-learning security prevents adversarial manipulation of improvement algorithms. | 3 | D/V |
| **10.9.5** | **Verify that** recursive self-improvement is bounded by formal safety constraints with mathematical proofs of convergence. | 3 | D/V |

---

### 参考情報

* [MITRE ATLAS adversary tactics for ML](https://atlas.mitre.org/)
* [NIST AI Risk Management Framework 1.0, 2023](https://nvlpubs.nist.gov/nistpubs/ai/nist.ai.100-1.pdf)
* [OWASP Top 10 for LLM Applications, 2025](https://owasp.org/www-project-top-10-for-large-language-model-applications/)
* [Adversarial Training: A Survey — Zhao et al., 2024](https://arxiv.org/abs/2410.15042)
* [RobustBench adversarial-robustness benchmark](https://robustbench.github.io/)
* [Membership-Inference & Model-Inversion Risk Survey, 2025](https://www.sciencedirect.com/science/article/abs/pii/S0950705125003867)
* [PURIFIER: Confidence-Score Defense against MI Attacks — AAAI 2023](https://ojs.aaai.org/index.php/AAAI/article/view/26289)
* [Model-Inversion Attacks & Defenses Survey — AI Review, 2025](https://link.springer.com/article/10.1007/s10462-025-11248-0)
* [Comprehensive Defense Framework Against Model Extraction — IEEE TDSC 2024](https://doi.org/10.1109/TDSC.2023.3261327)
* [Fragile Model Watermarking Survey — 2025](https://www.sciencedirect.com/science/article/abs/pii/S0165168425002026)
* [Data Poisoning in Deep Learning: A Survey — Zhao et al., 2025](https://arxiv.org/abs/2503.22759)
* [BDetCLIP: Multimodal Prompting Backdoor Detection — Niu et al., 2024](https://arxiv.org/abs/2405.15269)
